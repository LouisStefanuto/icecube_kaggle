{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182a84b3",
   "metadata": {
    "papermill": {
     "duration": 0.005167,
     "end_time": "2023-02-26T21:58:29.975749",
     "exception": false,
     "start_time": "2023-02-26T21:58:29.970582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4005bdbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:29.986031Z",
     "iopub.status.busy": "2023-02-26T21:58:29.985457Z",
     "iopub.status.idle": "2023-02-26T21:58:31.650341Z",
     "shell.execute_reply": "2023-02-26T21:58:31.649192Z"
    },
    "papermill": {
     "duration": 1.67361,
     "end_time": "2023-02-26T21:58:31.653490",
     "exception": false,
     "start_time": "2023-02-26T21:58:29.979880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6879068e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:31.665141Z",
     "iopub.status.busy": "2023-02-26T21:58:31.663137Z",
     "iopub.status.idle": "2023-02-26T21:58:43.930637Z",
     "shell.execute_reply": "2023-02-26T21:58:43.929436Z"
    },
    "papermill": {
     "duration": 12.275016,
     "end_time": "2023-02-26T21:58:43.933279",
     "exception": false,
     "start_time": "2023-02-26T21:58:31.658263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if device.type == 'cpu':\n",
    "    # CPU version\n",
    "    ! pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/pytorch-geometric/PyTorch-Geometric\n",
    "elif device.type == 'cuda':\n",
    "    # GPU version\n",
    "    ! pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/pytorchgeometric\n",
    "else:\n",
    "    raise Exception('Bruh.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c998c7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:43.942917Z",
     "iopub.status.busy": "2023-02-26T21:58:43.942601Z",
     "iopub.status.idle": "2023-02-26T21:58:47.664800Z",
     "shell.execute_reply": "2023-02-26T21:58:47.663746Z"
    },
    "papermill": {
     "duration": 3.729991,
     "end_time": "2023-02-26T21:58:47.667462",
     "exception": false,
     "start_time": "2023-02-26T21:58:43.937471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Add python files\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/icecube-py')\n",
    "from dataset import MyOwnDataset\n",
    "from metrics import angular_dist_score\n",
    "import pred_to_angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7a46f",
   "metadata": {
    "papermill": {
     "duration": 0.003561,
     "end_time": "2023-02-26T21:58:47.675075",
     "exception": false,
     "start_time": "2023-02-26T21:58:47.671514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d483a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:47.685187Z",
     "iopub.status.busy": "2023-02-26T21:58:47.684148Z",
     "iopub.status.idle": "2023-02-26T21:58:47.705422Z",
     "shell.execute_reply": "2023-02-26T21:58:47.704414Z"
    },
    "papermill": {
     "duration": 0.02863,
     "end_time": "2023-02-26T21:58:47.707592",
     "exception": false,
     "start_time": "2023-02-26T21:58:47.678962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, LeakyReLU\n",
    "from torch_geometric.nn import DynamicEdgeConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch import Tensor, LongTensor\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.utils.homophily import homophily\n",
    "from torch_geometric.nn.aggr import MultiAggregation, AttentionalAggregation\n",
    "\n",
    "\n",
    "class EdgeConvMLP(torch.nn.Module):\n",
    "    \"\"\"Basic convolutional block.\"\"\"\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            Linear(dim_in, dim_hidden),\n",
    "            LeakyReLU(),\n",
    "            Linear(dim_hidden, dim_out),\n",
    "            LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    \n",
    "class GateMLP(torch.nn.Module):\n",
    "    \"\"\"Basic convolutional block.\"\"\"\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            Linear(dim_in, dim_hidden),\n",
    "            LeakyReLU(),\n",
    "            Linear(dim_hidden, dim_out),\n",
    "            LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class DynEdgeAttention(torch.nn.Module):\n",
    "    \"\"\"Dynedge model from https://iopscience.iop.org/article/10.1088/1748-0221/17/11/P11003)\"\"\"\n",
    "    def __init__(self, num_node_features, dim_output, dropout_rate=0.):\n",
    "        super(DynEdgeAttention, self).__init__()\n",
    "        \n",
    "        torch.manual_seed(12345)\n",
    "        self.num_node_features = num_node_features\n",
    "        self.dim_output = dim_output\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.K = 8\n",
    "#         self.aggrs_list = ['mean', 'min' , 'max', 'sum', AttentionalAggregation(gate_nn=GateMLP(256, 512, 256))]\n",
    "        self.aggrs_list = [AttentionalAggregation(gate_nn=GateMLP(256, 64, 1))]\n",
    "\n",
    "        self.conv1 = DynamicEdgeConv(nn=EdgeConvMLP(2 * self.num_node_features, 336, 256), k=self.K)\n",
    "        self.conv2 = DynamicEdgeConv(nn=EdgeConvMLP(512, 336, 256), k=self.K)\n",
    "        self.conv3 = DynamicEdgeConv(nn=EdgeConvMLP(512, 336, 256), k=self.K)\n",
    "        self.conv4 = DynamicEdgeConv(nn=EdgeConvMLP(512, 336, 256), k=self.K)\n",
    "        \n",
    "        # final regressor\n",
    "        self.mlp1 = torch.nn.Sequential(\n",
    "            Linear(256 * 4 + self.num_node_features, 336),\n",
    "            LeakyReLU(),\n",
    "            Linear(336, 256),\n",
    "            LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.global_pool =  MultiAggregation(aggrs=self.aggrs_list)\n",
    "        \n",
    "#         mode_kwargs = {'in_channels': 256, 'out_channels': 256, 'num_heads': 16}\n",
    "#         self.global_pool =  MultiAggregation(aggrs=self.aggrs_list, mode='attn', mode_kwargs=mode_kwargs)\n",
    "\n",
    "#         AttentionalAggregation\n",
    "#         self.attentional_aggr = AttentionalAggregation(gate_nn=GateMLP(256, 512, 256))\n",
    "\n",
    "        self.mlp2 =  torch.nn.Sequential(\n",
    "            Linear(len(self.aggrs_list) * 256 + (4 + self.num_node_features), 128), # input depends of number of aggregating fns + 4 homophily + mean_node\n",
    "#             Linear(256 + (4 + self.num_node_features), 128),\n",
    "            LeakyReLU(),\n",
    "            Linear(128, self.dim_output)\n",
    "        )\n",
    "\n",
    "\n",
    "    def _calculate_global_variables(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: LongTensor,\n",
    "        batch: LongTensor,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Calculate global variables.\"\"\"\n",
    "        # Calculate homophily (scalar variables)\n",
    "        h_x = homophily(edge_index, x[:, 0], batch).reshape(-1, 1)\n",
    "        h_y = homophily(edge_index, x[:, 1], batch).reshape(-1, 1)\n",
    "        h_z = homophily(edge_index, x[:, 2], batch).reshape(-1, 1)\n",
    "        h_t = homophily(edge_index, x[:, 3], batch).reshape(-1, 1)\n",
    "        \n",
    "        # Calculate mean features\n",
    "        global_means = scatter_mean(x, batch, dim=0)\n",
    "\n",
    "        # Add global variables\n",
    "        global_variables = torch.cat([global_means, h_x, h_y, h_z, h_t], dim=-1)\n",
    "\n",
    "        return global_variables\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 0. Obtain global variables\n",
    "        global_x = self._calculate_global_variables(x, edge_index, batch)\n",
    "        \n",
    "        # 1. Obtain node embeddings at various embedding depths\n",
    "        x1 = self.conv1(x, batch)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        x3 = self.conv3(x2, batch)\n",
    "        x4 = self.conv4(x3, batch)\n",
    "\n",
    "        x = torch.cat([x, x1, x2, x3, x4], dim=-1)\n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "\n",
    "        # 2. Pooling        \n",
    "        x = self.global_pool(x, batch)\n",
    "            \n",
    "        x = torch.cat([global_x, x], dim=-1)\n",
    "\n",
    "        # 3. Apply a final MLP regressor\n",
    "        x = self.mlp2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a9e3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:47.716300Z",
     "iopub.status.busy": "2023-02-26T21:58:47.715960Z",
     "iopub.status.idle": "2023-02-26T21:58:51.532298Z",
     "shell.execute_reply": "2023-02-26T21:58:51.531295Z"
    },
    "papermill": {
     "duration": 3.823194,
     "end_time": "2023-02-26T21:58:51.534580",
     "exception": false,
     "start_time": "2023-02-26T21:58:47.711386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynEdgeAttention(\n",
       "  (conv1): DynamicEdgeConv(nn=EdgeConvMLP(\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=336, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=336, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  ), k=8)\n",
       "  (conv2): DynamicEdgeConv(nn=EdgeConvMLP(\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=336, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=336, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  ), k=8)\n",
       "  (conv3): DynamicEdgeConv(nn=EdgeConvMLP(\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=336, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=336, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  ), k=8)\n",
       "  (conv4): DynamicEdgeConv(nn=EdgeConvMLP(\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=336, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=336, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  ), k=8)\n",
       "  (mlp1): Sequential(\n",
       "    (0): Linear(in_features=1029, out_features=336, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=336, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (global_pool): MultiAggregation([\n",
       "    AttentionalAggregation(gate_nn=GateMLP(\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  ), nn=None),\n",
       "  ], mode=cat)\n",
       "  (mlp2): Sequential(\n",
       "    (0): Linear(in_features=265, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initalize your final model\n",
    "model = DynEdgeAttention(\n",
    "    num_node_features=5, \n",
    "    dim_output=3, \n",
    "    dropout_rate=0.\n",
    ").to(device)\n",
    "\n",
    "# Load model from path\n",
    "PATH_LOAD = '/kaggle/input/icecube-models/26-02-dynedgeattentionxyz-0to41-expected1.075.pt'\n",
    "\n",
    "target_mode = 'xyz' # angles / cossin / xyz\n",
    "\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    model.load_state_dict(torch.load(PATH_LOAD, map_location=torch.device('cpu')))\n",
    "else: # GPU - cuda\n",
    "    model.load_state_dict(torch.load(PATH_LOAD))\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725ca74",
   "metadata": {
    "papermill": {
     "duration": 0.003705,
     "end_time": "2023-02-26T21:58:51.542803",
     "exception": false,
     "start_time": "2023-02-26T21:58:51.539098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2844f0ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:51.552196Z",
     "iopub.status.busy": "2023-02-26T21:58:51.551646Z",
     "iopub.status.idle": "2023-02-26T21:58:51.641095Z",
     "shell.execute_reply": "2023-02-26T21:58:51.639388Z"
    },
    "papermill": {
     "duration": 0.096999,
     "end_time": "2023-02-26T21:58:51.643775",
     "exception": false,
     "start_time": "2023-02-26T21:58:51.546776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 ms, sys: 6.21 ms, total: 21.5 ms\n",
      "Wall time: 74.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>first_pulse_index</th>\n",
       "      <th>last_pulse_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>661</td>\n",
       "      <td>7344</td>\n",
       "      <td>299</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661</td>\n",
       "      <td>9482</td>\n",
       "      <td>335</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id  event_id  first_pulse_index  last_pulse_index\n",
       "0       661      2092                  0               298\n",
       "1       661      7344                299               334\n",
       "2       661      9482                335               377"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_meta_df = pd.read_parquet('/kaggle/input/icecube-neutrinos-in-deep-ice/test_meta.parquet')\n",
    "# test_meta_df = pd.read_parquet('/kaggle/input/smallermeta/val_meta_11_small.parquet')\n",
    "\n",
    "test_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "390f4147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:51.654128Z",
     "iopub.status.busy": "2023-02-26T21:58:51.653303Z",
     "iopub.status.idle": "2023-02-26T21:58:51.661792Z",
     "shell.execute_reply": "2023-02-26T21:58:51.660835Z"
    },
    "papermill": {
     "duration": 0.015461,
     "end_time": "2023-02-26T21:58:51.663761",
     "exception": false,
     "start_time": "2023-02-26T21:58:51.648300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([661])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_ids = test_meta_df.batch_id.unique()\n",
    "test_batch_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5e74e",
   "metadata": {
    "papermill": {
     "duration": 0.003845,
     "end_time": "2023-02-26T21:58:51.671953",
     "exception": false,
     "start_time": "2023-02-26T21:58:51.668108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c31be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:51.682724Z",
     "iopub.status.busy": "2023-02-26T21:58:51.681296Z",
     "iopub.status.idle": "2023-02-26T21:58:51.686233Z",
     "shell.execute_reply": "2023-02-26T21:58:51.685093Z"
    },
    "papermill": {
     "duration": 0.012158,
     "end_time": "2023-02-26T21:58:51.688413",
     "exception": false,
     "start_time": "2023-02-26T21:58:51.676255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs_pred = 100 # batchsize for predictions\n",
    "metrics = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422440b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:51.698667Z",
     "iopub.status.busy": "2023-02-26T21:58:51.698049Z",
     "iopub.status.idle": "2023-02-26T21:58:52.932253Z",
     "shell.execute_reply": "2023-02-26T21:58:52.930827Z"
    },
    "papermill": {
     "duration": 1.242325,
     "end_time": "2023-02-26T21:58:52.934840",
     "exception": false,
     "start_time": "2023-02-26T21:58:51.692515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== START PREDICTIONS BATCH 661 ===========\n",
      "Preparing batch 661 ...\n",
      "Loading meta ...\n",
      "Loading sensor ...\n",
      "Loading batch ...\n",
      "Complete.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 489 ms, sys: 127 ms, total: 616 ms\n",
      "Wall time: 1.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_azs = []\n",
    "list_zens = []\n",
    "list_event_ids = []\n",
    "\n",
    "for batch_id in test_batch_ids:\n",
    "    \n",
    "    print(f'=========== START PREDICTIONS BATCH {batch_id} ===========')\n",
    "        \n",
    "    dataset = MyOwnDataset(\n",
    "        batch_id, \n",
    "#         path_batch=f'/kaggle/input/smallermeta/batch_11_small.parquet',\n",
    "        path_batch=f'/kaggle/input/icecube-neutrinos-in-deep-ice/test/batch_{batch_id}.parquet',\n",
    "#         path_meta='/kaggle/input/smallermeta/val_meta_11_small.parquet',         \n",
    "        path_meta='/kaggle/input/icecube-neutrinos-in-deep-ice/test_meta.parquet', \n",
    "        path_sensor='/kaggle/input/icecube-neutrinos-in-deep-ice/sensor_geometry.csv',\n",
    "        target_mode=target_mode, \n",
    "        K=8, \n",
    "        features=['x', 'y', 'z', 'time', 'charge'], \n",
    "        threshold_events=500,\n",
    "        targets_test=True\n",
    "    )     \n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=bs_pred, shuffle=False)\n",
    "    \n",
    "    angle_error_sum = 0\n",
    "    \n",
    "    for id_batch, data in enumerate(tqdm(data_loader)): # Iterate over batches \n",
    "        \n",
    "        # Load data and labels to device and predict\n",
    "        events, event_ids = data\n",
    "        x, edge_index, batch = events.x.to(device), events.edge_index.to(device), events.batch.to(device)\n",
    "        \n",
    "        # for big events, do not compute\n",
    "        labels = events.y.to(device).reshape(-1, model.dim_output) # reshape bc model returns (batchsize, dim_out), while loader (idiot!) returns (dim_out*batchsize)\n",
    "\n",
    "        out = model(x, edge_index, batch) # Perform a single forward pass\n",
    "\n",
    "        # Convert preds to angles - same for labels \n",
    "        if target_mode == 'angles':\n",
    "            az_true, zen_true, az_pred, zen_pred = pred_to_angles.from_angles(out, labels)\n",
    "        if target_mode == 'cossin':        \n",
    "            az_true, zen_true, az_pred, zen_pred = pred_to_angles.from_cossin(out, labels)\n",
    "        if target_mode == 'xyz':\n",
    "            az_true, zen_true, az_pred, zen_pred = pred_to_angles.from_xyz(out, labels)\n",
    "\n",
    "        # Detach from GPU and send to CPU - convert to np to be accepted by host metric function\n",
    "        az_pred = az_pred.detach().cpu().numpy()\n",
    "        zen_pred = zen_pred.detach().cpu().numpy()\n",
    "        az_true = az_true.detach().cpu().numpy()\n",
    "        zen_true = zen_true.detach().cpu().numpy()\n",
    "            \n",
    "        # Metrics\n",
    "        if metrics:\n",
    "            angle_error = angular_dist_score(az_true, zen_true, az_pred, zen_pred)\n",
    "            angle_error_sum += angle_error * events.num_graphs\n",
    "\n",
    "            if id_batch % 100 == 0:\n",
    "                print(f'Batch {id_batch}/{len(data_loader)} - Angle error {angle_error}') \n",
    "        \n",
    "        list_event_ids.append(event_ids)\n",
    "        list_azs.append(az_pred)\n",
    "        list_zens.append(zen_pred)\n",
    "\n",
    "    if metrics:\n",
    "        print(angle_error_sum / len(data_loader.dataset))\n",
    "    \n",
    "    del dataset, data_loader\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb7d88",
   "metadata": {
    "papermill": {
     "duration": 0.004354,
     "end_time": "2023-02-26T21:58:52.944619",
     "exception": false,
     "start_time": "2023-02-26T21:58:52.940265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert preds to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5502a0f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:52.955939Z",
     "iopub.status.busy": "2023-02-26T21:58:52.955650Z",
     "iopub.status.idle": "2023-02-26T21:58:52.968875Z",
     "shell.execute_reply": "2023-02-26T21:58:52.968030Z"
    },
    "papermill": {
     "duration": 0.020685,
     "end_time": "2023-02-26T21:58:52.970919",
     "exception": false,
     "start_time": "2023-02-26T21:58:52.950234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2092</td>\n",
       "      <td>-0.319548</td>\n",
       "      <td>0.757679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7344</td>\n",
       "      <td>-0.103190</td>\n",
       "      <td>1.205279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9482</td>\n",
       "      <td>-1.918516</td>\n",
       "      <td>1.651994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id   azimuth    zenith\n",
       "0      2092 -0.319548  0.757679\n",
       "1      7344 -0.103190  1.205279\n",
       "2      9482 -1.918516  1.651994"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        'event_id': np.concatenate(list_event_ids, axis=0),  \n",
    "        'azimuth': np.concatenate(list_azs, axis=0),  \n",
    "        'zenith': np.concatenate(list_zens, axis=0)\n",
    "    }\n",
    ")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ca582e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-26T21:58:52.982007Z",
     "iopub.status.busy": "2023-02-26T21:58:52.981708Z",
     "iopub.status.idle": "2023-02-26T21:58:52.988268Z",
     "shell.execute_reply": "2023-02-26T21:58:52.987422Z"
    },
    "papermill": {
     "duration": 0.014558,
     "end_time": "2023-02-26T21:58:52.990180",
     "exception": false,
     "start_time": "2023-02-26T21:58:52.975622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428bb04",
   "metadata": {
    "papermill": {
     "duration": 0.004579,
     "end_time": "2023-02-26T21:58:52.999609",
     "exception": false,
     "start_time": "2023-02-26T21:58:52.995030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.201177,
   "end_time": "2023-02-26T21:58:54.427432",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-26T21:58:22.226255",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
